{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f128f28-37f9-4be1-9fad-37c8dae5f918",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8ca3a4-29d5-46d7-885b-2487c0971f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44acf5d4-612e-42ee-b1bf-3e37f7251645",
   "metadata": {},
   "source": [
    "### Define GridWorld Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af6172f-5fbd-4d6f-a186-0e69a3bc4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, size=5):  # default 5x5 grid\n",
    "        self.size = size\n",
    "        self.goal = (size - 1, size - 1)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent_pos = (0, 0)\n",
    "        return self.agent_pos\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.agent_pos\n",
    "        if action == 0:   # Up\n",
    "            x = max(x - 1, 0)\n",
    "        elif action == 1: # Down\n",
    "            x = min(x + 1, self.size - 1)\n",
    "        elif action == 2: # Left\n",
    "            y = max(y - 1, 0)\n",
    "        elif action == 3: # Right\n",
    "            y = min(y + 1, self.size - 1)\n",
    "\n",
    "        new_pos = (x, y)\n",
    "\n",
    "        if new_pos == self.agent_pos:\n",
    "            reward = -1\n",
    "        elif new_pos == self.goal:\n",
    "            reward = 10\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        self.agent_pos = new_pos\n",
    "        done = (new_pos == self.goal)\n",
    "\n",
    "        return new_pos, reward, done\n",
    "\n",
    "    def state_to_index(self, pos):\n",
    "        return pos[0] * self.size + pos[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4945018-4dd5-4c82-8ac7-2ee0989faa4c",
   "metadata": {},
   "source": [
    "### Define Q-learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d04f28-ef6e-41e7-a320-f736e6494a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.q_table = np.zeros((env.size * env.size, 4))  # states = 25 for 5x5, 4 actions\n",
    "        self.alpha = 0.1\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.1\n",
    "\n",
    "    def choose_action(self, state_index):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.randint(0, 3)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state_index])\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        predict = self.q_table[state][action]\n",
    "        target = reward + self.gamma * np.max(self.q_table[next_state])\n",
    "        self.q_table[state][action] += self.alpha * (target - predict)\n",
    "\n",
    "    def train(self, episodes=500):\n",
    "        for episode in range(episodes):\n",
    "            state_pos = self.env.reset()\n",
    "            state = self.env.state_to_index(state_pos)\n",
    "            done = False\n",
    "            step = 0\n",
    "\n",
    "            while not done and step < 50:\n",
    "                action = self.choose_action(state)\n",
    "                next_pos, reward, done = self.env.step(action)\n",
    "                next_state = self.env.state_to_index(next_pos)\n",
    "\n",
    "                self.learn(state, action, reward, next_state)\n",
    "\n",
    "                state = next_state\n",
    "                step += 1\n",
    "\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "\n",
    "            if episode % 50 == 0:\n",
    "                print(f\"Episode {episode} complete, Epsilon: {self.epsilon:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79f6c8-2669-44ae-9e01-326444cee24e",
   "metadata": {},
   "source": [
    "### Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247d0349-1a96-4965-aa7a-c78e95412ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for 5x5 grid...\n",
      "Episode 0 complete, Epsilon: 0.995\n",
      "Episode 50 complete, Epsilon: 0.774\n",
      "Episode 100 complete, Epsilon: 0.603\n",
      "Episode 150 complete, Epsilon: 0.469\n",
      "Episode 200 complete, Epsilon: 0.365\n",
      "Episode 250 complete, Epsilon: 0.284\n",
      "Episode 300 complete, Epsilon: 0.221\n",
      "Episode 350 complete, Epsilon: 0.172\n",
      "Episode 400 complete, Epsilon: 0.134\n",
      "Episode 450 complete, Epsilon: 0.104\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld()   # Create 5x5 grid environment\n",
    "agent = QLearningAgent(env)\n",
    "\n",
    "print(\"Training started for 5x5 grid...\")\n",
    "agent.train(episodes=500)  # Train agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3615ce0-486b-444d-ac83-c4f66db71859",
   "metadata": {},
   "source": [
    "### Save Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ac58547-8730-4d40-b586-21e421aa85c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Q-table saved to 'q_table.npy'.\n"
     ]
    }
   ],
   "source": [
    "np.save(\"q_table.npy\", agent.q_table)\n",
    "print(\"Training complete. Q-table saved to 'q_table.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2a9cb-d389-41e2-89c1-906f7d56c3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46132ac-9bba-4eeb-b1ac-b424fe0df26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60745e74-a837-41d8-92e3-9b1e643565c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ede43c-9047-42ed-ba51-a9ae65d78341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:msenv]",
   "language": "python",
   "name": "conda-env-msenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
